import itertools
import json
import logging
from functools import cached_property
from datetime import timedelta
from asgiref.sync import async_to_sync
from channels.db import database_sync_to_async
from channels.generic.websocket import AsyncJsonWebsocketConsumer, JsonWebsocketConsumer
from channels.exceptions import DenyConnection, StopConsumer
from channels.layers import get_channel_layer
from django.core.exceptions import ValidationError
from django.db import transaction
from django.utils import timezone
from django.utils.crypto import get_random_string

from reportcreator_api.pentests.models import PentestProject, ProjectNotebookPage, UserNotebookPage, \
    CollabEvent, CollabEventType, collab_context
from reportcreator_api.pentests.serializers import ProjectNotebookPageSerializer, UserNotebookPageSerializer
from reportcreator_api.utils.text_transformations import ChangeSet, Update, rebase_updates
from reportcreator_api.utils.history import history_context
from reportcreator_api.utils.utils import is_uuid, aretry


log = logging.getLogger(__name__)


class WebsocketConsumerBase(AsyncJsonWebsocketConsumer):
    last_permission_check_time = None

    async def websocket_connect(self, message):
        try:
            # Log connection
            user = '<none>'
            if self.scope.get('user') and not self.scope['user'].is_anonymous:
                user = self.scope['user'].username
            logging.info(f'CONNECT {self.scope['path']} (user={user})')

            # Set user.admin_permissions_enabled
            if self.scope.get('user') and self.scope.get('session', {}).get('admin_permissions_enabled'):
                setattr(self.scope['user'], 'admin_permissions_enabled', True)

            with history_context(history_user=self.scope.get('user')):
                return await super().websocket_connect(message)
        except Exception as ex:
            log.exception(ex)
            raise ex
    
    async def websocket_receive(self, message):
        try:
            if not await self.has_permission():
                await self.close()
                return

            with history_context(history_user=self.scope.get('user')):
                return await super().websocket_receive(message)
        except Exception as ex:
            log.exception(ex)
            raise ex
        
    async def websocket_disconnect(self, message):
        try:
            return await super().websocket_disconnect(message)
        except StopConsumer:
            user = '<none>'
            if self.scope.get('user') and not self.scope['user'].is_anonymous:
                user = self.scope['user'].username
            logging.info(f'DISCONNECT {self.scope['path']} (user={user})')
            raise
        except Exception as ex:
            log.exception(ex)
            raise ex
        
    async def dispatch(self, message):
        try:
            if not message.get('type', '').startswith('websocket.') and \
               (not self.last_permission_check_time or self.last_permission_check_time + timedelta(seconds=60) < timezone.now()):
                if not await self.has_permission():
                    await self.close()
                    return

            with history_context(history_user=self.scope.get('user')):
                return await super().dispatch(message)
        except StopConsumer:
            raise
        except Exception as ex:
            log.exception(ex)
            raise ex
    
    @property
    def group_name(self) -> str:
        raise NotImplementedError()
    
    @cached_property
    def client_id(self) -> str:
        return f'{self.scope['user'].id}/{get_random_string(8)}'
    
    async def has_permission(self):
        self.last_permission_check_time = timezone.now()
        return True
    
    async def get_initial_message(self):
        return None
    
    async def connect(self):
        if not await self.has_permission():
            raise DenyConnection()

        await super().connect()
        initial_msg = await self.get_initial_message()
        if initial_msg:
            await self.send_json(initial_msg)

        await self.channel_layer.group_add(self.group_name, self.channel_name)
    
    async def disconnect(self, close_code):
        await self.channel_layer.group_discard(self.group_name, self.channel_name)
        await super().disconnect(close_code)

    async def send_colllab_event(self, event):
        if not event:
            return
        await self.channel_layer.group_send(self.group_name, {
            'type': 'collab_event', 
            'id': str(event.id),
            'path': event.path,
        })
    
    async def collab_event(self, event):
        @database_sync_to_async
        def get_collab_event(id):
            return CollabEvent.objects.get(id=id)
        
        # Retry fetching event from DB: DB transactions can cause the channels event to arrive before event data is commited to the DB
        collab_event = await aretry(lambda: get_collab_event(event.get('id')), retry_for=CollabEvent.DoesNotExist)
        await self.send_json({
            'type': collab_event.type,
            'path': collab_event.path,
            'client_id': collab_event.client_id,
            'version': collab_event.version,
            **collab_event.data
        })


class NotesConsumerBase(WebsocketConsumerBase):
    serializer_class = None

    @property
    def related_id(self):
        raise NotImplementedError()
    
    def get_notes_queryset(self):
        raise NotImplementedError()
    
    def get_serializer(self, *args, **kwargs):
        return self.serializer_class(*args, **kwargs)

    @database_sync_to_async
    def get_initial_message(self):
        notes = list(self.get_notes_queryset()
            .order_by('created'))
        return {
            'type': 'init',
            'client_id': self.client_id,
            'version': max(n.updated.timestamp() for n in notes) if notes else 0,
            'data': {
                'notes': {n['id']: n for n in self.get_serializer(notes, many=True).data}
            }
        }
    
    async def receive_json(self, content, **kwargs):
        log.info(f'WebSocket receive_json: {content}')
        msg_type = content.get('type')
        if msg_type == CollabEventType.UPDATE_KEY:
            event = await self.do_update_key(content)
            await self.send_colllab_event(event)
        elif msg_type == CollabEventType.UPDATE_TEXT:
            event = await self.do_update_text(content)
            await self.send_colllab_event(event)
        else:
            raise ValueError(f'Invalid message type: {msg_type}')

    def get_note_for_update(self, path, valid_paths=None):
        if not isinstance(path, str):
            raise ValidationError('Invalid path')
        path_parts = path.split('.')
        if len(path_parts) < 3 or path_parts[0] != 'notes' or not is_uuid(path_parts[1]) or not (not valid_paths or '.'.join(path_parts[2:]) in valid_paths):
            raise ValidationError('Invalid path')
        note = self.get_notes_queryset() \
            .filter(note_id=path_parts[1]) \
            .select_for_update(of=['self'], no_key=True) \
            .first()
        if not note:
            raise ValidationError('Invalid path')
        return note, path_parts[2]

    @database_sync_to_async
    @transaction.atomic()
    def do_update_key(self, content):
        # Validate path and get note
        valid_paths = {k for k, f in self.get_serializer().fields.items() if not f.read_only} - {'title', 'text'}
        note, key = self.get_note_for_update(path=content.get('path'), valid_paths=valid_paths)

        # Update in DB
        serializer = self.get_serializer(instance=note, data={key: content.get('value')}, partial=True)
        serializer.is_valid(raise_exception=True)
        with collab_context(prevent_events=True):
            note = serializer.save()

        return CollabEvent.objects.create(
            related_id=self.related_id,
            path=content['path'],
            type=CollabEventType.UPDATE_KEY,
            created=note.updated,
            version=note.updated.timestamp(),
            client_id=self.client_id,
            data={
                'value': content['value']
            }
        )
    
    @database_sync_to_async
    @transaction.atomic()
    def do_update_text(self, content):
        # Validate path and get note
        if not content.get('updates', []):
            raise ValidationError('No updates')
        note, key = self.get_note_for_update(path=content.get('path'), valid_paths=['title', 'text'])

        version = content['version']
        # TODO: prevent updates for versions that are too old
        # * check if version is too old and if there are updates in between
        # * simple timestamp comparison is not enough, because when there were no updates in between, the version is still valid

        over_updates = CollabEvent.objects \
            .filter(related_id=self.related_id) \
            .filter(path=content['path']) \
            .filter(type=CollabEventType.UPDATE_TEXT) \
            .filter(version__gt=version) \
            .order_by('version')
        updates = rebase_updates(
            updates=[Update(client_id=self.client_id, version=version, changes=ChangeSet.from_dict(u['changes'])) for u in content.get('updates', [])],
            over=list(itertools.chain(*[[
                Update(client_id=e.client_id, version=e.version, changes=ChangeSet.from_dict(u['changes'])) 
                for u in e.data.get('updates', [])] for e in over_updates])),
        )

        log.info(f'Rebased updates: {updates=}')
        if not updates:
            return None

        # Update in DB
        changes = updates[0].changes
        for u in updates[1:]:
            changes = changes.compose(u.changes)
        log.info(f'Applying changes: {changes=} to "{json.dumps(note.text)}"')
        setattr(note, key, changes.apply(getattr(note, key) or ''))
        with collab_context(prevent_events=True):
            note.save()
        
        # Store OT event in DB
        version = note.updated.timestamp()
        return CollabEvent.objects.create(
            related_id=self.related_id,
            path=content['path'],
            type=CollabEventType.UPDATE_TEXT,
            created=note.updated,
            version=note.updated.timestamp(),
            client_id=self.client_id,
            data={
                'updates': [{'changes': u.changes.to_dict()} for u in updates]
            }
        )
    
    async def collab_event(self, event):
        if event.get('path', '').startswith('notes'):
            await super().collab_event(event)


class ProjectNotesConsumer(NotesConsumerBase):
    serializer_class = ProjectNotebookPageSerializer

    @property
    def related_id(self):
        return self.scope['url_route']['kwargs']['project_id']
    
    @property
    def group_name(self) -> str:
        return f'project_{self.related_id}'
    
    @database_sync_to_async
    def get_project(self):
        return PentestProject.objects \
            .only_permitted(self.scope['user']) \
            .filter(id=self.related_id) \
            .first()
    
    async def has_permission(self):
        self.last_permission_check_time = timezone.now()
        user = self.scope['user']
        project = await self.get_project()
        if not user or user.is_anonymous or not project:
            return False
        if project.readonly:
            return False
        return True
    
    def get_notes_queryset(self):
        return ProjectNotebookPage.objects \
            .filter(project_id=self.related_id) \
            .select_related('parent', 'assignee')


class UserNotesConsumer(NotesConsumerBase):
    serializer_class = UserNotebookPageSerializer

    @property
    def related_id(self):
        user_id = self.scope['url_route']['kwargs']['pentestuser_pk']
        if user_id == 'self':
            return self.scope['user'].id
        else:
            return user_id
    
    @property
    def group_name(self) -> str:
        return f'user_{self.related_id}'
    
    async def has_permission(self):
        self.last_permission_check_time = timezone.now()
        user = self.scope['user']
        if not user or user.is_anonymous:
            return False
        if str(user.id) == str(self.related_id):
            return True
        return False
    
    def get_notes_queryset(self):
        return UserNotebookPage.objects \
            .filter(user_id=self.related_id) \
            .select_related('parent')


def send_collab_event_project(event: CollabEvent):
    group_name = f'project_{event.related_id}'
    layer = get_channel_layer()
    async_to_sync(layer.group_send)(group_name, {
        'type': 'collab_event',
        'id': str(event.id),
        'path': event.path,
    })


def send_collab_event_user(event: CollabEvent):
    group_name = f'user_{event.related_id}'
    layer = get_channel_layer()
    async_to_sync(layer.group_send)(group_name, {
        'type': 'collab_event',
        'id': str(event.id),
        'path': event.path,
    })


class DemoConsumer(JsonWebsocketConsumer):
    def connect(self):
        self.accept()
        self.send_json({'message': 'Hello World'})

    def receive_json(self, data):
        self.send_json(data)



# TODO: concurrent editing
# * [ ] server config
#   * [x] uvicorn
#   * [x] asgi+channels
#   * [ ] channels layer: 
#     * [x] add postgres layer for self-hosted
#     * [x] has a max message size => circumvent via separate DB model and pass only model ID
#     * [ ] does not work with pgbouncer => affects SysReptor cloud, alternative: redis or rabbitmq?
# * [x] reverse proxy config
#   * [x] caddy => no config update required
#   * [x] nginx => requires config update
# * [ ] SysReptor cloud
#   * [ ] redis or rabbitmq instead of postgres channels layer
#   * [ ] nginx config update: allow websockets
# * [x] models
#   * [x] NotebookPage: remove lock_info
#   * [x] CollabEvent: id, parent_id, version, path, data
#   * [x] delete old CollabEvent in periodic_task (e.g. once per hour, older than 2 hours)
# * [x] consumers
#   * [x] project notes
#   * [x] user notes
# * [ ] sync with DB
#   * [x] websocket update => django ORM
#   * [ ] post_save signal => websocket update message
#     * [x] create
#     * [x] delete
#     * [x] sort
#     * [x] update_key
#     * [ ] update_text => get text diff and convert to ChangeSet
# * [ ] frontend
#   * [x] codemirror collab: emit/receive updates
#   * [x] emit/receive update.key messages
#   * [x] integrate to pinia store / state management
#   * [x] integrate codemirror collab with server
#   * [x] debounce/throttle updates in frontend: e.g. max. 1 per second
#   * [x] on websocket disconnect: show warning and reconnect button
#   * [x] fallback to API (read-only) if permission denied of websocket error
#   * [x] update EditToolbar usage
#   * [x] handle update_text for notes without active codemirror (apply updates in store instead of codemirror) => causes unselected notes to be out of sync
#   * [ ] on delete: if note is currently selected, navigate away
# * [ ] awareness
#   * [ ] frontend: show cursors of other users
#   * [ ] frontend: show user avatars in notes sidebar
#   * [ ] frontend: on connect/disconnect: clear local awareness data
#   * [ ] backend: on connect/disconnect: send event to all clients with user information (id, username, name, random color)
#   * [ ] frontend: on user connected: send all local awareness information
#   * [ ] backend: only broadcast awareness information, do not store it
#   * [ ] awareness info: current page, per-field selections+cursor
# * [ ] security
#   * [x] websocket authentication
#   * [x] permission checks
#   * [ ] close connection
#       * [ ] on logout
#       * [x] on project deletion
#       * [x] on project set readonly
#       * [x] on user removed from project
# * [ ] tests
#   * [x] test websocket authentication
#   * [x] test concurrent updates
#   * [x] test sync to DB
#   * [x] test sync to DB => history entry
#   * [x] test API update => update message
#   * [x] test save signal => update message
# * [ ] other
#   * [ ] update NOTICE
#   * [ ] remove excessive logging
#   * [ ] remove DemoConsumer

