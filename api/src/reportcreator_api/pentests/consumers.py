import itertools
import json
import logging
from datetime import timedelta
from functools import cached_property

from asgiref.sync import async_to_sync
from channels.db import database_sync_to_async
from channels.exceptions import DenyConnection, StopConsumer
from channels.generic.websocket import AsyncJsonWebsocketConsumer
from channels.layers import get_channel_layer
from django.core.exceptions import ValidationError
from django.core.serializers.json import DjangoJSONEncoder
from django.db import transaction
from django.db.models import Prefetch
from django.utils import timezone
from django.utils.crypto import get_random_string
from randomcolor import RandomColor

from reportcreator_api.pentests.customfields.types import FieldDataType
from reportcreator_api.pentests.customfields.utils import get_value_at_path, iterate_fields, set_value_at_path
from reportcreator_api.pentests.models import (
    CollabClientInfo,
    CollabEvent,
    CollabEventType,
    PentestFinding,
    PentestProject,
    ProjectNotebookPage,
    ReportSection,
    UserNotebookPage,
    collab_context,
)
from reportcreator_api.pentests.serializers.notes import ProjectNotebookPageSerializer, UserNotebookPageSerializer
from reportcreator_api.pentests.serializers.project import PentestFindingSerializer, ReportSectionSerializer
from reportcreator_api.users.serializers import PentestUserSerializer
from reportcreator_api.utils.history import history_context
from reportcreator_api.utils.text_transformations import EditorSelection, Update, rebase_updates
from reportcreator_api.utils.utils import aretry, is_uuid

log = logging.getLogger(__name__)


class WebsocketConsumerBase(AsyncJsonWebsocketConsumer):
    last_permission_check_time = None
    initial_path = None

    async def dispatch(self, message):
        try:
            if not message.get('type', '').startswith('websocket.') and not await self.check_permission(skip_on_recent_check=True):
                await self.close(code=4443)
                return

            with history_context(history_user=self.scope.get('user')):
                await super().dispatch(message)
        except StopConsumer:
            await self.delete_client_info()
            raise
        except Exception as ex:
            await self.delete_client_info()
            log.exception(ex)
            raise ex

    async def websocket_connect(self, message):
        # Log connection
        user = '<none>'
        if self.scope.get('user') and not self.scope['user'].is_anonymous:
            user = self.scope['user'].username
        logging.info(f'CONNECT {self.scope['path']} (user={user})')

        # Set user.admin_permissions_enabled
        if self.scope.get('user') and self.scope.get('session', {}).get('admin_permissions_enabled'):
            self.scope['user'].admin_permissions_enabled = True

        with history_context(history_user=self.scope.get('user')):
            return await super().websocket_connect(message)

    async def websocket_receive(self, message):
        event = await self.decode_json(message.get('text', '{}'))
        if event.get('type') == 'ping':
            await self.send_json({'type': 'ping'})
            return

        if not await self.check_permission():
            await self.close(code=4443)
            return

        with history_context(history_user=self.scope.get('user')):
            return await super().websocket_receive(message)

    async def websocket_disconnect(self, message):
        try:
            return await super().websocket_disconnect(message)
        except StopConsumer:
            user = '<none>'
            if self.scope.get('user') and not self.scope['user'].is_anonymous:
                user = self.scope['user'].username
            logging.info(f'DISCONNECT {self.scope['path']} (user={user})')
            raise

    async def encode_json(self, content):
        return json.dumps(content, cls=DjangoJSONEncoder)

    @property
    def group_name(self) -> str:
        raise NotImplementedError()

    @cached_property
    def client_id(self) -> str:
        return f'{self.scope['user'].id}/{get_random_string(8)}'

    @cached_property
    def client_color(self) -> str:
        return RandomColor(seed=get_random_string(8)).generate(luminosity='bright')[0]

    @database_sync_to_async
    def check_permission(self, skip_on_recent_check=False):
        # Skip permission check if it was done recently
        if skip_on_recent_check and self.last_permission_check_time and self.last_permission_check_time + timedelta(seconds=60) >= timezone.now():
            return True

        # Check if session is still valid
        session = self.scope.get('session')
        if not session or not session.session_key or \
           session.expire_date < timezone.now() or \
           not session.exists(session.session_key):
            return False

        # Check custom permissions
        res = self.has_permission()
        self.last_permission_check_time = timezone.now()
        return res

    def has_permission(self):
        return True

    @database_sync_to_async
    def create_client_info(self):
        CollabClientInfo.objects.create(
            related_id=self.related_id,
            user=self.scope['user'],
            client_id=self.client_id,
            client_color=self.client_color,
            path=self.initial_path,
        )

    @database_sync_to_async
    def delete_client_info(self):
        CollabClientInfo.objects \
            .filter(client_id=self.client_id) \
            .delete()

    async def get_initial_message(self):
        return None

    async def get_connect_message(self):
        return {
            'type': CollabEventType.CONNECT,
            'client_id': self.client_id,
            'path': self.initial_path,
            'client_color': self.client_color,
            'user': PentestUserSerializer(self.scope['user']).data,
        }

    async def get_disconnect_message(self):
        return {
            'type': CollabEventType.DISCONNECT,
            'client_id': self.client_id,
            'path': self.initial_path,
        }

    async def connect(self):
        if not await self.check_permission():
            raise DenyConnection()

        await super().connect()
        await self.create_client_info()
        if initial_msg := await self.get_initial_message():
            await self.send_json(initial_msg)

        await self.channel_layer.group_add(self.group_name, self.channel_name)
        if connect_msg := await self.get_connect_message():
            await self.send_colllab_event(connect_msg)

    async def disconnect(self, close_code):
        await self.channel_layer.group_discard(self.group_name, self.channel_name)
        await self.delete_client_info()
        if disconnect_msg := await self.get_disconnect_message():
            await self.send_colllab_event(disconnect_msg)
        await super().disconnect(close_code)

    async def send_colllab_event(self, event):
        if not event:
            return
        elif isinstance(event, CollabEvent):
            await self.channel_layer.group_send(self.group_name, {
                'type': 'collab_event',
                'id': str(event.id),
                'path': event.path,
            })
        else:
            await self.channel_layer.group_send(self.group_name, {
                'type': 'collab_event',
                'path': event.get('path'),
                'event': event,
            })

    async def collab_event(self, event):
        if event.get('id'):
            @database_sync_to_async
            def get_collab_event(id):
                return CollabEvent.objects.get(id=id)

            # Retry fetching event from DB: DB transactions can cause the channels event to arrive before event data is commited to the DB
            collab_event = await aretry(lambda: get_collab_event(event['id']), retry_for=CollabEvent.DoesNotExist)
            await self.send_json({
                'type': collab_event.type,
                'path': collab_event.path,
                'client_id': collab_event.client_id,
                'version': collab_event.version,
                **collab_event.data,
            })
        elif isinstance(event.get('event'), dict):
            await self.send_json(event['event'])


class NotesConsumerBase(WebsocketConsumerBase):
    serializer_class = None
    initial_path = 'notes'

    @property
    def related_id(self):
        raise NotImplementedError()

    def get_notes_queryset(self):
        raise NotImplementedError()

    def get_serializer(self, *args, **kwargs):
        return self.serializer_class(*args, **kwargs)

    @database_sync_to_async
    def get_initial_message(self):
        notes = list(self.get_notes_queryset()
            .order_by('created'))
        clients = CollabClientInfo.objects \
            .filter(related_id=self.related_id) \
            .filter(path__startswith='notes')
        return {
            'type': CollabEventType.INIT,
            'client_id': self.client_id,
            'client_color': self.client_color,
            'version': max(n.updated.timestamp() for n in notes) if notes else 0,
            'data': {
                'notes': {n['id']: n for n in self.get_serializer(notes, many=True).data},
            },
            'clients': [{
                'client_id': c.client_id,
                'client_color': c.client_color,
                'user': PentestUserSerializer(c.user).data,
                'path': c.path,
            } for c in clients],
        }

    async def receive_json(self, content, **kwargs):
        log.info(f'WebSocket receive_json: {content}')
        msg_type = content.get('type')
        if msg_type == CollabEventType.UPDATE_KEY:
            event = await self.do_update_key(content)
            await self.send_colllab_event(event)
        elif msg_type == CollabEventType.UPDATE_TEXT:
            event = await self.do_update_text(content)
            await self.send_colllab_event(event)
        elif msg_type == CollabEventType.AWARENESS:
            event = await self.do_update_awareness(content)
            await self.send_colllab_event(event)
        else:
            raise ValueError(f'Invalid message type: {msg_type}')

    def get_note_for_update(self, path, valid_paths=None):
        if not isinstance(path, str):
            raise ValidationError('Invalid path')
        path_parts = path.split('.')
        if len(path_parts) < 3 or path_parts[0] != 'notes' or not is_uuid(path_parts[1]) or not (not valid_paths or '.'.join(path_parts[2:]) in valid_paths):
            raise ValidationError('Invalid path')
        note = self.get_notes_queryset() \
            .filter(note_id=path_parts[1]) \
            .select_for_update(of=['self'], no_key=True) \
            .first()
        if not note:
            return None, None
        return note, path_parts[2]

    @database_sync_to_async
    @transaction.atomic()
    def do_update_key(self, content):
        # Validate path and get note
        valid_paths = {k for k, f in self.get_serializer().fields.items() if not f.read_only} - {'title', 'text'}
        note, key = self.get_note_for_update(path=content.get('path'), valid_paths=valid_paths)
        if not note:
            return None

        # Update in DB
        serializer = self.get_serializer(instance=note, data={key: content.get('value')}, partial=True)
        serializer.is_valid(raise_exception=True)
        with collab_context(prevent_events=True):
            note = serializer.save()

        return CollabEvent.objects.create(
            related_id=self.related_id,
            path=content['path'],
            type=CollabEventType.UPDATE_KEY,
            created=note.updated,
            version=note.updated.timestamp(),
            client_id=self.client_id,
            data={
                'value': content['value'],
            },
        )

    @database_sync_to_async
    @transaction.atomic()
    def do_update_text(self, content):
        # Validate path and get note
        if not content.get('updates', []):
            raise ValidationError('No updates')
        note, key = self.get_note_for_update(path=content.get('path'), valid_paths=['title', 'text'])
        if not note:
            return None

        version = content['version']
        # TODO: reject updates for versions that are too old
        # * check if version is too old and if there are updates in between
        # * simple timestamp comparison is not enough, because when there were no updates in between, the version is still valid
        # * checking version < note.version is not enough, because of concurrent updates (e.g. old version, update1 succeeds, update2 fails because of updated version)

        # Rebase updates
        over_updates = CollabEvent.objects \
            .filter(related_id=self.related_id) \
            .filter(path=content['path']) \
            .filter(type=CollabEventType.UPDATE_TEXT) \
            .filter(version__gt=version) \
            .order_by('version')
        updates, selection = rebase_updates(
            updates=[Update.from_dict(u | {'client_id': self.client_id, 'version': version}) for u in content.get('updates', [])],
            selection=EditorSelection.from_dict(content['selection']) if content.get('selection') else None,
            over=list(itertools.chain(*[[
                Update.from_dict(u | {'client_id': e.client_id, 'version': version})
                for u in e.data.get('updates', [])] for e in over_updates])),
        )
        if not updates:
            return None

        # Update in DB
        changes = updates[0].changes
        for u in updates[1:]:
            changes = changes.compose(u.changes)
        setattr(note, key, changes.apply(getattr(note, key) or ''))
        with collab_context(prevent_events=True):
            note.save()

        # Update client info
        CollabClientInfo.objects \
            .filter(client_id=self.client_id) \
            .update(path=content['path'])

        # Store OT event in DB
        return CollabEvent.objects.create(
            related_id=self.related_id,
            path=content['path'],
            type=CollabEventType.UPDATE_TEXT,
            created=note.updated,
            version=note.updated.timestamp(),
            client_id=self.client_id,
            data={
                'updates': [u.to_dict() for u in updates],
                **({'selection': selection.to_dict()} if selection else {}),
            },
        )

    @database_sync_to_async
    def do_update_awareness(self, content):
        path = content.get('path') or 'notes'

        version = content['version']

        selection = None
        if content.get('path') and content.get('selection'):
            over_events = CollabEvent.objects \
                .filter(related_id=self.related_id) \
                .filter(path=path) \
                .filter(type=CollabEventType.UPDATE_TEXT) \
                .filter(version__gt=version) \
                .order_by('version')
            over_updates = list(itertools.chain(*[[
                Update.from_dict(u | {'client_id': self.client_id, 'version': version})
                for u in e.data.get('updates', [])] for e in over_events]))
            version = max([e.version for e in over_updates] + [version])

            selection = EditorSelection.from_dict(content['selection'])
            for u in over_updates:
                selection = selection.map(u.changes)

        # Update client info
        CollabClientInfo.objects \
            .filter(client_id=self.client_id) \
            .update(path=path)

        return {
            'type': CollabEventType.AWARENESS,
            'path': path,
            'client_id': self.client_id,
            **({'selection': selection.to_dict()} if selection else {}),
        }

    async def collab_event(self, event):
        if (event.get('path') or '').startswith('notes'):
            await super().collab_event(event)


class ProjectNotesConsumer(NotesConsumerBase):
    serializer_class = ProjectNotebookPageSerializer

    @property
    def related_id(self):
        return self.scope['url_route']['kwargs']['project_id']

    @property
    def group_name(self) -> str:
        return f'project_{self.related_id}'

    def get_project(self):
        return PentestProject.objects \
            .only_permitted(self.scope['user']) \
            .filter(id=self.related_id) \
            .first()

    def has_permission(self):
        user = self.scope['user']
        project = self.get_project()
        if not user or user.is_anonymous or not project:
            return False
        if project.readonly:
            return False
        return True

    def get_notes_queryset(self):
        return ProjectNotebookPage.objects \
            .filter(project_id=self.related_id) \
            .select_related('parent', 'assignee')


class UserNotesConsumer(NotesConsumerBase):
    serializer_class = UserNotebookPageSerializer

    @property
    def related_id(self):
        user_id = self.scope['url_route']['kwargs']['pentestuser_pk']
        if user_id == 'self':
            return self.scope['user'].id
        else:
            return user_id

    @property
    def group_name(self) -> str:
        return f'user_{self.related_id}'

    def has_permission(self):
        user = self.scope['user']
        if not user or user.is_anonymous:
            return False
        if str(user.id) == str(self.related_id):
            return True
        return False

    def get_notes_queryset(self):
        return UserNotebookPage.objects \
            .filter(user_id=self.related_id) \
            .select_related('parent')


class ProjectReportingConsumer(WebsocketConsumerBase):
    @property
    def related_id(self):
        return self.scope['url_route']['kwargs']['project_id']

    @property
    def group_name(self) -> str:
        return f'project_{self.related_id}'

    def has_permission(self):
        user = self.scope['user']
        project = self.get_project()
        if not user or user.is_anonymous or not project:
            return False
        if project.readonly:
            return False
        return True

    def get_project(self, prefetch_related=False):
        qs = PentestProject.objects \
            .only_permitted(self.scope['user']) \
            .filter(id=self.related_id)
        if prefetch_related:
            qs = qs \
                .select_related('project_type') \
                .prefetch_related(
                    Prefetch('sections', queryset=ReportSection.objects.select_related('assignee')),
                    Prefetch('findings', queryset=PentestFinding.objects.select_related('assignee')),
                )
        return qs.first()

    @database_sync_to_async
    def get_initial_message(self):
        project = self.get_project(prefetch_related=True)
        if not project:
            return None
        sections = list(project.sections.all())
        findings = list(project.findings.all())
        clients = CollabClientInfo.objects \
            .filter(related_id=self.related_id) \
            .exclude(path__startswith='notes')
        return {
            'type': CollabEventType.INIT,
            'client_id': self.client_id,
            'client_color': self.client_color,
            'version': max([o.updated.timestamp() for o in sections + findings + [project]]),
            'data': {
                'sections': {s['id']: s for s in ReportSectionSerializer(sections, many=True).data},
                'findings': {f['id']: f for f in PentestFindingSerializer(findings, many=True).data},
            },
            'clients': [{
                'client_id': c.client_id,
                'client_color': c.client_color,
                'user': PentestUserSerializer(c.user).data,
                'path': c.path,
            } for c in clients],
        }

    async def receive_json(self, content, **kwargs):
        log.info(f'WebSocket receive_json: {content}')
        msg_type = content.get('type')
        if msg_type == CollabEventType.UPDATE_KEY:
            event = await self.do_update_key(content)
            await self.send_colllab_event(event)
        elif msg_type == CollabEventType.UPDATE_TEXT:
            event = await self.do_update_text(content)
            await self.send_colllab_event(event)
        elif msg_type == CollabEventType.AWARENESS:
            event = await self.do_update_awareness(content)
            await self.send_colllab_event(event)
        else:
            raise ValueError(f'Invalid message type: {msg_type}')

    def get_object_for_update(self, path):
        if not isinstance(path, str):
            raise ValidationError('Invalid path')
        path_parts = tuple(path.split('.'))
        if len(path_parts) < 3 or not (path_parts[0] == 'sections' or (path_parts[0] == 'findings' and is_uuid(path_parts[1]))):
            raise ValidationError('Invalid path')

        if path_parts[0] == 'sections':
            obj_qs = ReportSection.objects.filter(section_id=path_parts[1])
            serializer_class = ReportSectionSerializer
        elif path_parts[0] == 'findings' and is_uuid(path_parts[1]):
            obj_qs = PentestFinding.objects.filter(finding_id=path_parts[1])
            serializer_class = PentestFindingSerializer
        else:
            raise ValidationError('Invalid path')

        obj = obj_qs \
            .filter(project_id=self.related_id) \
            .select_related('assignee', 'project__project_type') \
            .select_for_update(of=['self'], no_key=True) \
            .first()
        if not obj:
            return None, None, None

        # Validate path in top-level or in field definition
        if path_parts[2] == 'data':
            for path, _value, definition in iterate_fields(obj.data, obj.field_definition):
                if path == path_parts[3:]:
                    return obj, path_parts[2:], definition
            raise ValidationError('Invalid path')
        else:
            valid_paths = {k for k, f in serializer_class().fields.items() if not f.read_only}
            if len(path_parts) > 3 or path_parts[2] not in valid_paths:
                raise ValidationError('Invalid path')

            return obj, path_parts[2:], None

    @database_sync_to_async
    @transaction.atomic()
    def do_update_key(self, content):
        # Validate path and get section/finding
        obj, path, definition = self.get_object_for_update(content.get('path'))
        if not obj or (definition and definition.type in [FieldDataType.MARKDOWN, FieldDataType.STRING]):
            return None

        # Update data in DB
        if definition:
            set_value_at_path(obj.data, path[1:], content.get('value'))
            serializer_data = {'data': obj.data}
        else:
            serializer_data = {path[0]: content.get('value')}
        serializer = (ReportSectionSerializer if isinstance(obj, ReportSection) else PentestFindingSerializer)(instance=obj, data=serializer_data, partial=True)
        serializer.is_valid(raise_exception=True)
        with collab_context(prevent_events=True):
            obj = serializer.save()

        return CollabEvent.objects.create(
            related_id=self.related_id,
            path=content['path'],
            type=CollabEventType.UPDATE_KEY,
            created=obj.updated,
            version=obj.updated.timestamp(),
            client_id=self.client_id,
            data={
                'value': content['value'],
            },
        )

    @database_sync_to_async
    @transaction.atomic()
    def do_update_text(self, content):
        obj, path, definition = self.get_object_for_update(content.get('path'))
        if not obj or not definition or definition.type not in [FieldDataType.MARKDOWN, FieldDataType.STRING]:
            return None

        version = content['version']
        # TODO: reject updates for versions that are too old

        # Rebase updates
        over_updates = CollabEvent.objects \
            .filter(related_id=self.related_id) \
            .filter(path=content['path']) \
            .filter(type=CollabEventType.UPDATE_TEXT) \
            .filter(version__gt=version) \
            .order_by('version')
        updates, selection = rebase_updates(
            updates=[Update.from_dict(u | {'client_id': self.client_id, 'version': version}) for u in content.get('updates', [])],
            selection=EditorSelection.from_dict(content['selection']) if content.get('selection') else None,
            over=list(itertools.chain(*[[
                Update.from_dict(u | {'client_id': e.client_id, 'version': version})
                for u in e.data.get('updates', [])] for e in over_updates])),
        )
        if not updates:
            return None

        # Update in DB
        changes = updates[0].changes
        for u in updates[1:]:
            changes = changes.compose(u.changes)
        updated_data = obj.data
        set_value_at_path(updated_data, path[1:], changes.apply(get_value_at_path(updated_data, path[1:]) or ''))
        obj.update_data(updated_data)
        with collab_context(prevent_events=True):
            obj.save()

        # Update client info
        CollabClientInfo.objects \
            .filter(client_id=self.client_id) \
            .update(path=content['path'])

        # Store OT event in DB
        return CollabEvent.objects.create(
            related_id=self.related_id,
            path=content['path'],
            type=CollabEventType.UPDATE_TEXT,
            created=obj.updated,
            version=obj.updated.timestamp(),
            client_id=self.client_id,
            data={
                'updates': [u.to_dict() for u in updates],
                **({'selection': selection.to_dict()} if selection else {}),
            },
        )

    @database_sync_to_async
    def do_update_awareness(self, content):
        path = content.get('path') or 'notes'

        version = content['version']

        selection = None
        if content.get('path') and content.get('selection'):
            over_events = CollabEvent.objects \
                .filter(related_id=self.related_id) \
                .filter(path=path) \
                .filter(type=CollabEventType.UPDATE_TEXT) \
                .filter(version__gt=version) \
                .order_by('version')
            over_updates = list(itertools.chain(*[[
                Update.from_dict(u | {'client_id': self.client_id, 'version': version})
                for u in e.data.get('updates', [])] for e in over_events]))
            version = max([e.version for e in over_updates] + [version])

            selection = EditorSelection.from_dict(content['selection'])
            for u in over_updates:
                selection = selection.map(u.changes)

        # Update client info
        CollabClientInfo.objects \
            .filter(client_id=self.client_id) \
            .update(path=path)

        return {
            'type': CollabEventType.AWARENESS,
            'path': path,
            'client_id': self.client_id,
            **({'selection': selection.to_dict()} if selection else {}),
        }

    async def collab_event(self, event):
        if not (event.get('path') or '').startswith('notes'):
            await super().collab_event(event)


def send_collab_event_project(event: CollabEvent):
    group_name = f'project_{event.related_id}'
    layer = get_channel_layer()
    async_to_sync(layer.group_send)(group_name, {
        'type': 'collab_event',
        'id': str(event.id),
        'path': event.path,
    })


def send_collab_event_user(event: CollabEvent):
    group_name = f'user_{event.related_id}'
    layer = get_channel_layer()
    async_to_sync(layer.group_send)(group_name, {
        'type': 'collab_event',
        'id': str(event.id),
        'path': event.path,
    })


# TODO: Collaborative editing in findings and sections
# * [x] remove lock_info
#     * [x] models
#     * [x] API
#     * [x] serializers
#     * [x] frontend UI
#     * [x] update tests
#     * [x] frontend useProjectLockEdit
# * [ ] operational transformation
#   * [ ] nested lists
#       * [ ] add item
#       * [ ] remove item
#       * [ ] sort list
#   * [ ] nested fields
# * [ ] consumer
#     * [x] broadcast collab events for path not startswith "notes"
#     * [ ] broadcast project events: override_finding_order, project_type
#     * [x] handle custom_fields in finding.data and section.data
#     * [ ] handle list field operations: add, delete, sort
# * [ ] post_save signals
#     * [ ] create finding, section
#     * [ ] delete finding, section
#     * [ ] update_key finding, section, project
#     * [ ] sort findings
#     * [ ] project type changed or field definition updated
# * [ ] frontend
#     * [x] store: useCollab
#     * [x] finding list: useCollab
#     * [x] finding list: fallback to API
#     * [x] finding/section detail: useCollab
#     * [x] locking in community edition
#     * [x] DynamicInputField: emit collab events
#     * [x] add CollabAvatar to finding/section list
#     * [ ] how to retrieve changes for project.project_type and project.override_finding_order
#     * [ ] handle updated override_finding_order
#     * [ ] handle updated project_type
#  [ ] tests
#     * [ ] test sync to DB
#     * [ ] test sync to DB => history entry
#     * [ ] test API update => update event
#     * [ ] test save signal => update event
#     * [ ] test concurrent update to custom_fields
#     * [ ] test update assignee
#     * [ ] test update user field
#     * [ ] test update_key in custom_fields
