import itertools
import logging
from channels.db import database_sync_to_async
from channels.generic.websocket import AsyncJsonWebsocketConsumer, JsonWebsocketConsumer
from channels.exceptions import DenyConnection, StopConsumer
from django.core.exceptions import ValidationError
from django.db import transaction

from reportcreator_api.pentests.models import PentestProject
from reportcreator_api.pentests.models.notes import ProjectNotebookPage
from reportcreator_api.pentests.models import OperationalTransformationEvent
from reportcreator_api.pentests.serializers.notes import ProjectNotebookPageSerializer
from reportcreator_api.utils.concurrent_editing import Update, rebase_updates
from reportcreator_api.utils.history import history_context
from reportcreator_api.utils.utils import is_uuid


log = logging.getLogger(__name__)


class WebsocketConsumerBase(AsyncJsonWebsocketConsumer):
    async def websocket_connect(self, message):
        try:
            user = '<none>'
            if self.scope.get('user') and not self.scope['user'].is_anonymous:
                user = self.scope['user'].username
            logging.info(f'CONNECT {self.scope['path']} (user={user})')
            with history_context(history_user=self.scope.get('user')):
                return await super().websocket_connect(message)
        except Exception as ex:
            log.exception(ex)
            raise ex
    
    async def websocket_receive(self, message):
        try:
            with history_context(history_user=self.scope.get('user')):
                return await super().websocket_receive(message)
        except Exception as ex:
            log.exception(ex)
            raise ex
        
    async def websocket_disconnect(self, message):
        try:
            return await super().websocket_disconnect(message)
        except StopConsumer:
            logging.info(f'DISCONNECT {self.scope['path']} (user={self.scope['user'].username})')
            raise
        except Exception as ex:
            log.exception(ex)
            raise ex
        
    async def dispatch(self, message):
        try:
            with history_context(history_user=self.scope.get('user')):
                return await super().dispatch(message)
        except StopConsumer:
            raise
        except Exception as ex:
            log.exception(ex)
            raise ex
    
    @property
    def group_name(self) -> str:
        raise NotImplementedError
    
    async def has_permission(self):
        return True
    
    async def get_initial_message(self):
        return None
    
    async def __call__(self, scope, receive, send):
        return await super().__call__(scope, receive, send)
    
    async def connect(self):
        if not await self.has_permission():
            raise DenyConnection()

        await super().connect()
        initial_msg = await self.get_initial_message()
        if initial_msg:
            await self.send_json(initial_msg)

        await self.channel_layer.group_add(self.group_name, self.channel_name)
    
    async def disconnect(self, close_code):
        await self.channel_layer.group_discard(self.group_name, self.channel_name)
        await super().disconnect(close_code)


class ProjectNotesConsumer(WebsocketConsumerBase):
    def connect(self):
        self.text_updates = {}
        return super().connect()

    async def has_permission(self):
        user = self.scope['user']
        project = await self.get_project()
        if not user or user.is_anonymous or not project:
            return False
        if project.readonly:
            return False
        return True
    
    @property
    def project_id(self):
        return self.scope['url_route']['kwargs']['project_id']
    
    @database_sync_to_async
    def get_project(self):
        return PentestProject.objects \
            .only_permitted(self.scope['user']) \
            .filter(id=self.project_id) \
            .first()
    
    @property
    def group_name(self) -> str:
        return f'project_notes_{self.project_id}'
    
    @database_sync_to_async
    def get_initial_message(self):
        notes = list(ProjectNotebookPage.objects \
            .filter(project_id=self.project_id) \
            .select_related('parent', 'assignee', 'lock_info_data__user') \
            .order_by('created'))
        return {
            'type': 'init',
            'version': max(n.updated.timestamp() for n in notes) if notes else 0,
            'data': {
                'notes': {n['id']: n for n in ProjectNotebookPageSerializer(notes, many=True).data}
            }
        }
    
    async def receive_json(self, content, **kwargs):
        log.info(f'WebSocket receive_json: {content}')
        msg_type = content.get('type')
        if msg_type == 'update.key':
            event = await self.do_update_key(content)
            await self.send_colllab_event(event)
        elif msg_type == 'update.text':
            event = await self.do_update_text(content)
            await self.send_colllab_event(event)
        else:
            raise ValueError(f'Invalid message type: {msg_type}')
        
    def get_note_for_update(self, path, valid_paths=None):
        if not isinstance(path, str):
            raise ValidationError('Invalid path')
        path_parts = path.split('.')
        if len(path_parts) < 3 or path_parts[0] != 'notes' or not is_uuid(path_parts[1]) or not (not valid_paths or '.'.join(path_parts[2:]) in valid_paths):
            raise ValidationError('Invalid path')
        note = ProjectNotebookPage.objects \
            .filter(project_id=self.project_id) \
            .filter(note_id=path_parts[1]) \
            .select_related('parent') \
            .select_for_update(of=['self'], no_key=True) \
            .first()
        if not note:
            raise ValidationError('Invalid path')
        return note, path_parts[2]

    @database_sync_to_async
    @transaction.atomic()
    def do_update_key(self, content):
        # Validate path and get note
        valid_paths = {k for k, f in ProjectNotebookPageSerializer().fields.items() if not f.read_only} - {'title', 'text'}
        note, key = self.get_note_for_update(path=content.get('path'), valid_paths=valid_paths)

        # Update in DB
        serializer = ProjectNotebookPageSerializer(instance=note, data={key: content.get('value')}, partial=True)
        serializer.is_valid(raise_exception=True)
        note = serializer.save()

        return OperationalTransformationEvent.objects.create(
            related_id=self.project_id,
            path=content['path'],
            type='collab.update.key',
            created=note.updated,
            version=note.updated.timestamp(),
            data={
                'value': content['value']
            }
        )

    @database_sync_to_async
    @transaction.atomic()
    def do_update_text(self, content):
        # Validate path and get note
        if not content.get('updates', []):
            raise ValidationError('No updates')
        note, key = self.get_note_for_update(path=content.get('path'), valid_paths=['title', 'text'])

        version = min([u['version'] for u in content.get('updates', [])])
        # TODO: prevent updates for versions that are too old
        # * check if version is too old and if there are updates in between
        # * simple timestamp comparison is not enough, because when there were no updates in between, the version is still valid

        over_updates = OperationalTransformationEvent.objects \
            .filter(related_id=self.project_id) \
            .filter(path=content['path']) \
            .filter(type='collab.update.text') \
            .filter(version__gt=version) \
            .order_by('version') \
            .values('data')
        updates = rebase_updates(
            updates=[Update.from_dict(u) for u in content.get('updates', [])],
            over=[Update.from_dict(u) for u in itertools.chain(*[e['data'].get('updates', []) for e in over_updates])],
        )
        log.info(f'Rebased updates: {updates=}')
        if not updates:
            return None

        # Update in DB
        changes = updates[0].changes
        for u in updates[1:]:
            changes = changes.compose(u.changes)
        logging.info(f'Applying changes: {changes=} to "{note.text}"')
        setattr(note, key, changes.apply(getattr(note, key) or ''))
        note.save()
        
        # Store OT event in DB
        version = note.updated.timestamp()
        for u in updates:
            u.version = version
        return OperationalTransformationEvent.objects.create(
            related_id=self.project_id,
            path=content['path'],
            type='collab.update.text',
            created=note.updated,
            version=version,
            data={
                'updates': [u.to_dict() for u in updates]
            }
        )
    
    async def send_colllab_event(self, event):
        if not event:
            return
        await self.channel_layer.group_send(self.group_name, {
            'type': 'collab_event', 
            'id': str(event.id),
        })
    
    async def collab_event(self, event):
        @database_sync_to_async
        def get_collab_event(id):
            return OperationalTransformationEvent.objects.get(id=id)
        
        collab_event = await get_collab_event(event.get('id'))
        await self.send_json({
            'type': collab_event.type,
            'path': collab_event.path,
            'version': collab_event.version,
            **collab_event.data
        })


class DemoConsumer(JsonWebsocketConsumer):
    def connect(self):
        self.accept()
        self.send_json({'message': 'Hello World'})

    def receive_json(self, data):
        self.send_json(data)



# TODO: concurrent editing
# * [ ] server config
#   * [x] uvicorn
#   * [x] asgi+channels
#   * [ ] channels layer: postgres
#     * [ ] does not work with pgbouncer => affects SysReptor cloud, alternative: redis or rabbitmq?
#     * [ ] has a max message size
# * [x] reverse proxy config
#   * [x] caddy => no config update required
#   * [x] nginx => requires config update
# * [ ] SysReptor cloud
#   * [ ] redis or rabbitmq instead of postgres channels layer
#   * [ ] nginx config update: allow websockets
# * [ ] models
#   * [ ] NotebookPage: remove lock_info
#   * [x] OperationalTransformationEvent: id, parent_id, version, path, data
#   * [ ] delete old OperationalTransformationEvent in periodic_task (e.g. once per hour, older than 2 hours)
# * [ ] consumers
#   * [ ] project notes
#   * [ ] user notes
# * [ ] sync with DB
#   * [x] websocket update => django ORM
#   * [ ] post_save signal => websocket update message
# * [ ] frontend
#   * [ ] codemirror collab: emit/receive updates
#   * [ ] emit/receive update.key messages
#   * [ ] integrate to pinia store / state management
#   * [ ] fallback to locking if no websocket is supported ???
#   * [ ] integrate codemirror collab with server
# * [ ] security
#   * [x] websocket authentication
#   * [x] permission checks
#   * [ ] close connection
#       * [ ] on logout
#       * [ ] on project deletion
#       * [ ] on project set readonly
#       * [ ] on user removed from project
# * [ ] tests
#   * [ ] test websocket authentication
#   * [ ] test concurrent updates
#   * [ ] test sync to DB
#   * [ ] test sync to DB => history entry
#   * [ ] test API update => update message
#   * [ ] test save signal => update message
# * [ ] other
#   * [ ] update NOTICE
